apiVersion: opentelemetry.io/v1alpha1
kind: OpenTelemetryCollector
metadata:
  name: {{ .Values.collector.name }} # the Operator automatically appends -collector in the name
  namespace: {{ .Release.Namespace }}
spec:
  image: {{ .Values.collector.image }}:{{ .Values.collector.tag }}
  mode: deployment
  replicas: {{ .Values.collector.replicas }}
  podAnnotations:
    fluentbit.io/exclude: "true"
  resources:
{{ toYaml .Values.collector.resources | indent 4 }}
  env:
    - name: KUBE_NODE_NAME
      valueFrom:
        fieldRef:
          fieldPath: spec.nodeName
    - name: KUBE_POD_NAME
      valueFrom:
        fieldRef:
          fieldPath: metadata.name
  volumeMounts:
    # Mount the volumes to the collector container
    - name: varlogpods
      mountPath: /var/log/pods
      readOnly: true
    - name: varlibdockercontainers
      mountPath: /var/lib/docker/containers
      readOnly: true
          
  volumes:
  # Typically the collector will want access to pod logs and container logs
    - name: varlogpods
      hostPath:
        path: /var/log/pods
    - name: varlibdockercontainers
      hostPath:
        path: /var/lib/docker/containers

  config: |
    receivers:
      zipkin:
      
      otlp:
        protocols:
          grpc:
          http:
            include_metadata: true

      prometheus:
        config:
          global:
            scrape_interval: {{ .Values.prometheus.scrapeInterval }} # 60s is the default
          scrape_configs:

            - job_name: k8s
              kubernetes_sd_configs:
              - role: pod
              relabel_configs:
              - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
                regex: "true"
                action: keep
              - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
                action: replace
                target_label: __address__
                regex: ([^:]+)(?::\d+)?;(\d+)
                # escaped $1:$2
                replacement: $$1:$$2
              metric_relabel_configs:
              - source_labels: [__name__]
                regex: "(request_duration_seconds.*|response_duration_seconds.*)"
                action: keep

            {{ if .Values.kubeStateMetricsChart.enabled }}
            - job_name: kube-state-metrics
              kubernetes_sd_configs:
              - role: endpoints
              relabel_configs:
              - source_labels: [__meta_kubernetes_service_label_app_kubernetes_io_name]
                regex: kube-state-metrics
                replacement: $$1
                action: keep
              - action: labelmap
                regex: __meta_kubernetes_service_label_(.+)
              - source_labels: [__meta_kubernetes_namespace]
                action: replace
                target_label: k8s_namespace
              - source_labels: [__meta_kubernetes_service_name]
                action: replace
                target_label: k8s_sname
            {{ end }}             

            {{- if .Values.nodeExporterChart.enabled}}
            - job_name: 'node-exporter'
              kubernetes_sd_configs:
                - role: endpoints
              relabel_configs:
              - source_labels: [__meta_kubernetes_endpoints_name]
                regex: '.*-node-exporter'
                action: keep
            {{- end }}

      prometheus/self:
        config:
          scrape_configs:
            - job_name: 'otel-collector'
              scrape_interval: {{ .Values.prometheus.scrapeInterval }} # By default, scrape targets every 60 seconds.
              static_configs:
                - targets: [ '0.0.0.0:8888' ]
    
    processors:
      batch:

      memory_limiter:
        check_interval: 1s
        limit_percentage: 50
        spike_limit_percentage: 30

      resource:
        attributes:
        - key: edge.layer
          value: {{ .Values.metadata.networkLayer }}
          action: insert
        - key: edge.region
          value: {{ .Values.metadata.region }}
          action: insert
        - key: k8s.cluster.name
          value: {{ .Values.metadata.clusterName }}
          action: insert
      
      k8sattributes:
        auth_type: "serviceAccount"
        passthrough: true # running as gateway config (mode: deployment)
        # filter:
        #   node_from_env_var: KUBE_NODE_NAME

        extract:
          metadata:
            - k8s.pod.name
            - k8s.pod.uid
            - k8s.deployment.name
            - k8s.namespace.name
            - k8s.node.name
            - k8s.pod.start_time

        pod_association: # How to associate the data to a pod (order matters)
        - sources: # First try to use the value of the resource attribute k8s.pod.ip
            - from: resource_attribute
              name: k8s.pod.ip
        - sources: # Then try to use the value of the resource attribute k8s.pod.uid
            - from: resource_attribute
              name: k8s.pod.uid
        - sources: # If neither of those work, use the request's connection to get the pod IP.
            - from: connection
    
    extensions:
      health_check: {}

    exporters:

      logging:
        verbosity: {{ .Values.logging.verbosity }}


      {{- if .Values.exporters.parentOtlp.enabled }}
      # Parent exporter for all logs, traces and metrics.
      otlphttp:
        endpoint: {{ required "Provide a value for Parent OTLP endpoint" .Values.exporters.parentOtlp.endpoint }}
        tls:
          insecure: true #TODO this will be removed in the future and usage of certs will be added
      {{ end }}

      {{- if .Values.exporters.azuremonitor.enabled }}
      azuremonitor:
        instrumentation_key: {{ required "Provide a value for Azure Monitor Instrumentation Key" .Values.exporters.azuremonitor.instrumentationKey | quote }}
        spaneventsenabled: true
        maxbatchinterval: 60s
      {{- end }}

      {{- if .Values.exporters.prometheus.enabled }}
      prometheusremotewrite:
        endpoint: {{ required "Provide a value for Prometheus remote write endpoint" .Values.exporters.prometheus.endpoint }}
      {{- end }}

      {{- if .Values.exporters.loki.enabled }}
      loki:
        endpoint: {{ required "Provide a value for Loki endpoint" .Values.exporters.loki.endpoint }}
      {{- end }}


      {{- if .Values.exporters.tempo.enabled }}
      otlp/2:
        endpoint: {{ required "Provide a value for Tempo endpoint" .Values.exporters.tempo.endpoint }}
        tls:
          insecure: true
      {{- end }}

      {{ if .Values.exporters.jaeger.enabled }}
      otlp/3:
        endpoint: {{ required "Provide a value for Jaeger endpoint" .Values.exporters.jaeger.endpoint }}
        tls:
          insecure: true
      {{ end }}
    
    service:
      pipelines:
        traces:
          receivers: [otlp,zipkin]
          processors: [memory_limiter, resource, k8sattributes, batch]
          exporters:
            {{ if .Values.exporters.parentOtlp.enabled }}- otlphttp{{- end}}
            {{ if .Values.exporters.azuremonitor.enabled }}- azuremonitor{{- end}}
            {{ if .Values.exporters.tempo.enabled }}- otlp/2{{- end}}
            {{ if .Values.exporters.jaeger.enabled }}- otlp/3{{- end}}
            {{ if .Values.logging.enableInPipelines }}- logging{{- end}}
        metrics:
          receivers: [prometheus, prometheus/self, otlp]
          processors: [memory_limiter, resource, k8sattributes, batch]
          exporters:
            {{ if .Values.exporters.parentOtlp.enabled }}- otlphttp{{- end}}
            {{ if .Values.exporters.azuremonitor.enabled }}- azuremonitor{{- end}}
            {{ if .Values.exporters.prometheus.enabled }}- prometheusremotewrite{{- end}}
            {{ if .Values.logging.enableInPipelines }}- logging{{- end}}
        logs:
          receivers: [otlp]
          processors: [memory_limiter, resource, k8sattributes, batch]
          exporters:
            {{ if .Values.exporters.parentOtlp.enabled }}- otlphttp{{- end}}
            {{ if .Values.exporters.azuremonitor.enabled }}- azuremonitor{{- end}}
            {{ if .Values.exporters.loki.enabled }}- loki{{ end }}
            {{ if .Values.logging.enableInPipelines }}- logging{{- end}}